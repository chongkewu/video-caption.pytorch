{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000\n",
      "vocab size is  16860\n",
      "number of train videos:  6501\n",
      "number of val videos:  500\n",
      "number of test videos:  2999\n",
      "load feats from ['data/feats/resnet152']\n",
      "max sequence length in data is 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chongke/anaconda3/envs/my_env/lib/python3.6/site-packages/torch/nn/modules/rnn.py:51: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n",
      "/home/chongke/anaconda3/envs/my_env/lib/python3.6/site-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init COCO-EVAL scorer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chongke/anaconda3/envs/my_env/lib/python3.6/site-packages/torch/nn/functional.py:1339: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 25970, 'reflen': 25896, 'guess': [25970, 22971, 19972, 16973], 'correct': [18938, 9429, 4168, 1629]}\n",
      "ratio:1.002858\n",
      "Bleu_1: 0.729\n",
      "Bleu_2: 0.547\n",
      "Bleu_3: 0.397\n",
      "Bleu_4: 0.278\n",
      "computing METEOR score...\n",
      "METEOR: 0.249\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.539\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.343\n",
      "{'Bleu_1': 0.7292260300346273, 'Bleu_2': 0.5471091124081876, 'Bleu_3': 0.3967814405238057, 'Bleu_4': 0.27826214630402224, 'METEOR': 0.24875412760972368, 'ROUGE_L': 0.5394962946542005, 'CIDEr': 0.34307183701377975}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from models import EncoderRNN, DecoderRNN, S2VTAttModel, S2VTModel\n",
    "from dataloader import VideoDataset\n",
    "import misc.utils as utils\n",
    "from misc.cocoeval import suppress_stdout_stderr, COCOScorer\n",
    "import numpy as np\n",
    "\n",
    "from pandas.io.json import json_normalize\n",
    "import pandas as pd\n",
    "\n",
    "def convert_data_to_coco_scorer_format(data_frame):\n",
    "        gts = {}\n",
    "        for row in zip(data_frame[\"caption\"], data_frame[\"video_id\"]):\n",
    "            if row[1] in gts:\n",
    "                gts[row[1]].append(\n",
    "                    {'image_id': row[1], 'cap_id': len(gts[row[1]]), 'caption': row[0]})\n",
    "            else:\n",
    "                gts[row[1]] = []\n",
    "                gts[row[1]].append(\n",
    "                    {'image_id': row[1], 'cap_id': len(gts[row[1]]), 'caption': row[0]})\n",
    "        return gts\n",
    "\n",
    "tail = [str(i) for i in range(0,3001,50)];\n",
    "for t in tail:\n",
    "    \n",
    "    print(t)\n",
    "    args = {'recover_opt': 'data/save/opt_info.json', 'saved_model': 'data/save_533PJ/model_50.pth', 'dump_json': 1, 'results_path': 'results/model_50', 'dump_path': 0, 'gpu': '0', 'batch_size': 25, 'sample_max': 1, 'temperature': 1.0, 'beam_size': 1}\n",
    "\n",
    "\n",
    "    args['saved_model'] = 'data/save_533PJ_2layer/model_'+t+'.pth';\n",
    "    args['results_path'] = 'results_533PJ_2layer/model_' + t;\n",
    "\n",
    "    opt = json.load(open(args[\"recover_opt\"]))\n",
    "    for k, v in args.items():\n",
    "            opt[k] = v\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = opt[\"gpu\"]\n",
    "    with torch.no_grad():\n",
    "        dataset = VideoDataset(opt, \"test\")\n",
    "\n",
    "        opt[\"vocab_size\"] = dataset.get_vocab_size()\n",
    "\n",
    "        opt[\"seq_length\"] = dataset.max_len\n",
    "\n",
    "        encoder = EncoderRNN(opt[\"dim_vid\"], opt[\"dim_hidden\"], bidirectional=opt[\"bidirectional\"], input_dropout_p=opt[\"input_dropout_p\"], rnn_dropout_p=opt[\"rnn_dropout_p\"]);\n",
    "        decoder = DecoderRNN(opt[\"vocab_size\"], opt[\"max_len\"], opt[\"dim_hidden\"], opt[\"dim_word\"], input_dropout_p=opt[\"input_dropout_p\"], rnn_dropout_p=opt[\"rnn_dropout_p\"], bidirectional=opt[\"bidirectional\"]);\n",
    "        model = S2VTAttModel(encoder, decoder).cuda()\n",
    "\n",
    "        model.load_state_dict(torch.load(opt[\"saved_model\"]))\n",
    "\n",
    "        crit = utils.LanguageModelCriterion()\n",
    "\n",
    "        model.encoder.rnn.bidirectional = bool(model.encoder.rnn.bidirectional)\n",
    "\n",
    "        vocab = dataset.get_vocab()\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        loader = DataLoader(dataset, batch_size=opt[\"batch_size\"], shuffle=True)\n",
    "\n",
    "        scorer = COCOScorer()\n",
    "\n",
    "        gt_dataframe = json_normalize(\n",
    "                json.load(open(opt[\"input_json\"]))['sentences'])\n",
    "\n",
    "\n",
    "\n",
    "        gts = convert_data_to_coco_scorer_format(gt_dataframe)\n",
    "        results = []\n",
    "        samples = {}\n",
    "    for data in loader:\n",
    "        # forward the model to get loss\n",
    "        fc_feats = data['fc_feats'].cuda()\n",
    "        labels = data['labels'].cuda()\n",
    "        masks = data['masks'].cuda()\n",
    "        video_ids = data['video_ids']\n",
    "\n",
    "        # forward the model to also get generated samples for each image\n",
    "        with torch.no_grad():\n",
    "            seq_probs, seq_preds = model(\n",
    "                fc_feats, mode='inference', opt=opt)\n",
    "\n",
    "            sents = utils.decode_sequence(vocab, seq_preds)\n",
    "\n",
    "            for k, sent in enumerate(sents):\n",
    "                video_id = video_ids[k]\n",
    "                samples[video_id] = [{'image_id': video_id, 'caption': sent}]\n",
    "\n",
    "    with suppress_stdout_stderr():\n",
    "        valid_score = scorer.score(gts, samples, samples.keys())\n",
    "    results.append(valid_score)\n",
    "    print(valid_score)\n",
    "\n",
    "    if not os.path.exists(opt[\"results_path\"]):\n",
    "        os.makedirs(opt[\"results_path\"])\n",
    "\n",
    "    with open(os.path.join(opt[\"results_path\"], \"scores.txt\"), 'a') as scores_table:\n",
    "        scores_table.write(json.dumps(results[0]) + \"\\n\")\n",
    "    with open(os.path.join(opt[\"results_path\"], opt[\"model\"].split(\"/\")[-1].split('.')[0] + \".json\"), 'w') as prediction_results:\n",
    "        json.dump({\"predictions\": samples, \"scores\": valid_score}, prediction_results)\n",
    "    del model\n",
    "    del encoder\n",
    "    del decoder\n",
    "    del results\n",
    "    del samples\n",
    "    del gts\n",
    "    del gt_dataframe\n",
    "    del seq_probs\n",
    "    del seq_preds\n",
    "    del sents\n",
    "    del fc_feats\n",
    "    del labels\n",
    "    del masks\n",
    "    del dataset\n",
    "    del scorer\n",
    "    del loader\n",
    "    del crit\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> torch.Size([24, 28])\n",
      "<class 'torch.Tensor'> torch.Size([24, 28])\n",
      "<class 'torch.Tensor'> torch.Size([24, 20, 28])\n",
      "<class 'torch.Tensor'> torch.Size([24, 40, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chongke/anaconda3/envs/my_env/lib/python3.6/site-packages/torch/distributed/distributed_c10d.py:100: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead\n",
      "  warnings.warn(\"torch.distributed.reduce_op is deprecated, please use \"\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import gc\n",
    "for obj in gc.get_objects():\n",
    "    try:\n",
    "        if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):\n",
    "            print(type(obj), obj.size())\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}