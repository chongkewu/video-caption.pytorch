{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from models import EncoderRNN, DecoderRNN, S2VTAttModel, S2VTModel\n",
    "from dataloader import VideoDataset\n",
    "import misc.utils as utils\n",
    "from misc.cocoeval import suppress_stdout_stderr, COCOScorer\n",
    "\n",
    "from pandas.io.json import json_normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "args = {'recover_opt': 'data/save/opt_info.json', 'saved_model': 'data/save/model_50.pth', 'dump_json': 1, 'results_path': 'results/', 'dump_path': 0, 'gpu': '0', 'batch_size': 25, 'sample_max': 1, 'temperature': 1.0, 'beam_size': 1}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt = json.load(open(args[\"recover_opt\"]))\n",
    "for k, v in args.items():\n",
    "        opt[k] = v\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = opt[\"gpu\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size is  16860\n",
      "number of train videos:  6501\n",
      "number of val videos:  500\n",
      "number of test videos:  2999\n",
      "load feats from ['data/feats/resnet152']\n",
      "max sequence length in data is 28\n"
     ]
    }
   ],
   "source": [
    "dataset = VideoDataset(opt, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt[\"vocab_size\"] = dataset.get_vocab_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt[\"seq_length\"] = dataset.max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'S2VTAttModel'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt[\"model\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chongke/anaconda3/lib/python3.6/site-packages/torch/nn/modules/rnn.py:51: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    }
   ],
   "source": [
    "encoder = EncoderRNN(opt[\"dim_vid\"], opt[\"dim_hidden\"], bidirectional=opt[\"bidirectional\"],\n",
    "                             input_dropout_p=opt[\"input_dropout_p\"], rnn_dropout_p=opt[\"rnn_dropout_p\"]);\n",
    "decoder = DecoderRNN(opt[\"vocab_size\"], opt[\"max_len\"], opt[\"dim_hidden\"], opt[\"dim_word\"],\n",
    "                             input_dropout_p=opt[\"input_dropout_p\"],\n",
    "                             rnn_dropout_p=opt[\"rnn_dropout_p\"], bidirectional=opt[\"bidirectional\"]);\n",
    "model = S2VTAttModel(encoder, decoder).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(opt[\"saved_model\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chongke/anaconda3/lib/python3.6/site-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "crit = utils.LanguageModelCriterion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.encoder.rnn.bidirectional = bool(model.encoder.rnn.bidirectional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab = dataset.get_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "S2VTAttModel(\n",
       "  (encoder): EncoderRNN(\n",
       "    (vid2hid): Linear(in_features=2048, out_features=512, bias=True)\n",
       "    (input_dropout): Dropout(p=0.2, inplace=False)\n",
       "    (rnn): GRU(512, 512, batch_first=True, dropout=0.5)\n",
       "  )\n",
       "  (decoder): DecoderRNN(\n",
       "    (input_dropout): Dropout(p=0.2, inplace=False)\n",
       "    (embedding): Embedding(16860, 512)\n",
       "    (attention): Attention(\n",
       "      (linear1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "      (linear2): Linear(in_features=512, out_features=1, bias=False)\n",
       "    )\n",
       "    (rnn): GRU(1024, 512, batch_first=True, dropout=0.5)\n",
       "    (out): Linear(in_features=512, out_features=16860, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loader = DataLoader(dataset, batch_size=opt[\"batch_size\"], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init COCO-EVAL scorer\n"
     ]
    }
   ],
   "source": [
    "scorer = COCOScorer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gt_dataframe = json_normalize(\n",
    "        json.load(open(opt[\"input_json\"]))['sentences'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_data_to_coco_scorer_format(data_frame):\n",
    "    gts = {}\n",
    "    for row in zip(data_frame[\"caption\"], data_frame[\"video_id\"]):\n",
    "        if row[1] in gts:\n",
    "            gts[row[1]].append(\n",
    "                {'image_id': row[1], 'cap_id': len(gts[row[1]]), 'caption': row[0]})\n",
    "        else:\n",
    "            gts[row[1]] = []\n",
    "            gts[row[1]].append(\n",
    "                {'image_id': row[1], 'cap_id': len(gts[row[1]]), 'caption': row[0]})\n",
    "    return gts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "gts = convert_data_to_coco_scorer_format(gt_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7f6d6ef8e908>\n"
     ]
    }
   ],
   "source": [
    "print(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = next(iter(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([25, 28])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xdata['labels'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# forward the model to get loss\n",
    "fc_feats = data['fc_feats'].cuda()\n",
    "labels = data['labels'].cuda()\n",
    "masks = data['masks'].cuda()\n",
    "video_ids = data['video_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([25, 28])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chongke/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py:1339: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    }
   ],
   "source": [
    "# forward the model to also get generated samples for each image\n",
    "with torch.no_grad():\n",
    "    seq_probs, seq_preds = model(\n",
    "        fc_feats, mode='inference', opt=opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sents = utils.decode_sequence(vocab, seq_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['video8680',\n",
       " 'video8334',\n",
       " 'video9525',\n",
       " 'video8070',\n",
       " 'video7328',\n",
       " 'video8052',\n",
       " 'video8675',\n",
       " 'video9433',\n",
       " 'video7620',\n",
       " 'video7963',\n",
       " 'video7715',\n",
       " 'video8565',\n",
       " 'video8844',\n",
       " 'video9121',\n",
       " 'video7742',\n",
       " 'video7974',\n",
       " 'video9780',\n",
       " 'video9555',\n",
       " 'video7514',\n",
       " 'video8163',\n",
       " 'video8846',\n",
       " 'video9756',\n",
       " 'video7708',\n",
       " 'video7153',\n",
       " 'video8125']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a woman is talking about a movie',\n",
       " 'a cartoon character is flying',\n",
       " 'a man is talking about a fish',\n",
       " 'a man is driving a car in a video game',\n",
       " 'a cartoon character is flying a sword',\n",
       " 'a man is dancing',\n",
       " 'a soccer player celebrates',\n",
       " 'a woman is talking about a movie',\n",
       " 'a woman is talking about a movie',\n",
       " 'a man is working with a machine',\n",
       " 'a woman is singing',\n",
       " 'a man is talking about a video game',\n",
       " 'a woman is dancing',\n",
       " 'a man is jumping on a trampoline',\n",
       " 'a man is showing how to use a computer',\n",
       " 'a woman is talking about a movie',\n",
       " 'a woman is talking about a movie',\n",
       " 'a man is singing a song',\n",
       " 'a man is talking about a video game',\n",
       " 'a man is talking about a movie',\n",
       " 'a man is swimming in a pool',\n",
       " 'a woman is talking about a movie',\n",
       " 'a cartoon of a boy and a girl are talking',\n",
       " 'a man is playing basketball',\n",
       " 'a man is talking about a video game']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>caption</th>\n",
       "      <th>sen_id</th>\n",
       "      <th>video_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>119100</th>\n",
       "      <td>a drone is crashed in the bushes</td>\n",
       "      <td>119100</td>\n",
       "      <td>video8125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119101</th>\n",
       "      <td>a man crashed on a human sized paper airplane</td>\n",
       "      <td>119101</td>\n",
       "      <td>video8125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119102</th>\n",
       "      <td>a man crashes a personal aircraft</td>\n",
       "      <td>119102</td>\n",
       "      <td>video8125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119103</th>\n",
       "      <td>a man crashes into the ground</td>\n",
       "      <td>119103</td>\n",
       "      <td>video8125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119104</th>\n",
       "      <td>a man crashes when he flies a remote flyer</td>\n",
       "      <td>119104</td>\n",
       "      <td>video8125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119105</th>\n",
       "      <td>a man hanging from his flying drone</td>\n",
       "      <td>119105</td>\n",
       "      <td>video8125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119106</th>\n",
       "      <td>a man in a flying contraption crashes in a field</td>\n",
       "      <td>119106</td>\n",
       "      <td>video8125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119107</th>\n",
       "      <td>a man is crashing</td>\n",
       "      <td>119107</td>\n",
       "      <td>video8125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119108</th>\n",
       "      <td>a man is getting carried away by something</td>\n",
       "      <td>119108</td>\n",
       "      <td>video8125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119109</th>\n",
       "      <td>a man is landing with a radio</td>\n",
       "      <td>119109</td>\n",
       "      <td>video8125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119110</th>\n",
       "      <td>a man is yelling about his technology</td>\n",
       "      <td>119110</td>\n",
       "      <td>video8125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119111</th>\n",
       "      <td>a person is hanging in the air</td>\n",
       "      <td>119111</td>\n",
       "      <td>video8125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119112</th>\n",
       "      <td>man crashed into bushes</td>\n",
       "      <td>119112</td>\n",
       "      <td>video8125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119113</th>\n",
       "      <td>man falls into some bushes and his friends com...</td>\n",
       "      <td>119113</td>\n",
       "      <td>video8125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119114</th>\n",
       "      <td>person recklessly flying on a drone style airc...</td>\n",
       "      <td>119114</td>\n",
       "      <td>video8125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119115</th>\n",
       "      <td>someone is zip lining</td>\n",
       "      <td>119115</td>\n",
       "      <td>video8125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119116</th>\n",
       "      <td>the man landed on the ground</td>\n",
       "      <td>119116</td>\n",
       "      <td>video8125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119117</th>\n",
       "      <td>two men filming an outdoor skydiving themed sk...</td>\n",
       "      <td>119117</td>\n",
       "      <td>video8125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119118</th>\n",
       "      <td>a man crashes a personal aircraft</td>\n",
       "      <td>119118</td>\n",
       "      <td>video8125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119119</th>\n",
       "      <td>a man in a flying contraption crashes in a field</td>\n",
       "      <td>119119</td>\n",
       "      <td>video8125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  caption  sen_id   video_id\n",
       "119100                   a drone is crashed in the bushes  119100  video8125\n",
       "119101      a man crashed on a human sized paper airplane  119101  video8125\n",
       "119102                  a man crashes a personal aircraft  119102  video8125\n",
       "119103                      a man crashes into the ground  119103  video8125\n",
       "119104         a man crashes when he flies a remote flyer  119104  video8125\n",
       "119105                a man hanging from his flying drone  119105  video8125\n",
       "119106   a man in a flying contraption crashes in a field  119106  video8125\n",
       "119107                                  a man is crashing  119107  video8125\n",
       "119108         a man is getting carried away by something  119108  video8125\n",
       "119109                      a man is landing with a radio  119109  video8125\n",
       "119110              a man is yelling about his technology  119110  video8125\n",
       "119111                     a person is hanging in the air  119111  video8125\n",
       "119112                            man crashed into bushes  119112  video8125\n",
       "119113  man falls into some bushes and his friends com...  119113  video8125\n",
       "119114  person recklessly flying on a drone style airc...  119114  video8125\n",
       "119115                              someone is zip lining  119115  video8125\n",
       "119116                       the man landed on the ground  119116  video8125\n",
       "119117  two men filming an outdoor skydiving themed sk...  119117  video8125\n",
       "119118                  a man crashes a personal aircraft  119118  video8125\n",
       "119119   a man in a flying contraption crashes in a field  119119  video8125"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_dataframe.loc[gt_dataframe.index[gt_dataframe['video_id'] == 'video8125']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
