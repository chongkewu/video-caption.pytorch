{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from models import EncoderRNN, DecoderRNN, S2VTAttModel, S2VTModel\n",
    "from dataloader import VideoDataset\n",
    "import misc.utils as utils\n",
    "from misc.cocoeval import suppress_stdout_stderr, COCOScorer\n",
    "import numpy as np\n",
    "\n",
    "from pandas.io.json import json_normalize\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "args = {'recover_opt': 'data/save/opt_info.json', 'saved_model': 'data/save/model_50.pth', 'dump_json': 1, 'results_path': 'results/', 'dump_path': 0, 'gpu': '0', 'batch_size': 25, 'sample_max': 1, 'temperature': 1.0, 'beam_size': 1}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt = json.load(open(args[\"recover_opt\"]))\n",
    "for k, v in args.items():\n",
    "        opt[k] = v\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = opt[\"gpu\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size is  16860\n",
      "number of train videos:  6501\n",
      "number of val videos:  500\n",
      "number of test videos:  2999\n",
      "load feats from ['data/feats/resnet152']\n",
      "max sequence length in data is 28\n"
     ]
    }
   ],
   "source": [
    "dataset = VideoDataset(opt, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt[\"vocab_size\"] = dataset.get_vocab_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt[\"seq_length\"] = dataset.max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'S2VTAttModel'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt[\"model\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chongke/anaconda3/envs/my_env/lib/python3.6/site-packages/torch/nn/modules/rnn.py:51: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    }
   ],
   "source": [
    "encoder = EncoderRNN(opt[\"dim_vid\"], opt[\"dim_hidden\"], bidirectional=opt[\"bidirectional\"],\n",
    "                             input_dropout_p=opt[\"input_dropout_p\"], rnn_dropout_p=opt[\"rnn_dropout_p\"]);\n",
    "decoder = DecoderRNN(opt[\"vocab_size\"], opt[\"max_len\"], opt[\"dim_hidden\"], opt[\"dim_word\"],\n",
    "                             input_dropout_p=opt[\"input_dropout_p\"],\n",
    "                             rnn_dropout_p=opt[\"rnn_dropout_p\"], bidirectional=opt[\"bidirectional\"]);\n",
    "model = S2VTAttModel(encoder, decoder).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(opt[\"saved_model\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chongke/anaconda3/envs/my_env/lib/python3.6/site-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "crit = utils.LanguageModelCriterion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.encoder.rnn.bidirectional = bool(model.encoder.rnn.bidirectional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab = dataset.get_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "S2VTAttModel(\n",
       "  (encoder): EncoderRNN(\n",
       "    (vid2hid): Linear(in_features=2048, out_features=512, bias=True)\n",
       "    (input_dropout): Dropout(p=0.2, inplace=False)\n",
       "    (rnn): GRU(512, 512, batch_first=True, dropout=0.5)\n",
       "  )\n",
       "  (decoder): DecoderRNN(\n",
       "    (input_dropout): Dropout(p=0.2, inplace=False)\n",
       "    (embedding): Embedding(16860, 512)\n",
       "    (attention): Attention(\n",
       "      (linear1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "      (linear2): Linear(in_features=512, out_features=1, bias=False)\n",
       "    )\n",
       "    (rnn): GRU(1024, 512, batch_first=True, dropout=0.5)\n",
       "    (out): Linear(in_features=512, out_features=16860, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# loader = DataLoader(dataset, batch_size=opt[\"batch_size\"], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loader = DataLoader(dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init COCO-EVAL scorer\n"
     ]
    }
   ],
   "source": [
    "scorer = COCOScorer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gt_dataframe = json_normalize(\n",
    "        json.load(open(opt[\"input_json\"]))['sentences'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_data_to_coco_scorer_format(data_frame):\n",
    "    gts = {}\n",
    "    for row in zip(data_frame[\"caption\"], data_frame[\"video_id\"]):\n",
    "        if row[1] in gts:\n",
    "            gts[row[1]].append(\n",
    "                {'image_id': row[1], 'cap_id': len(gts[row[1]]), 'caption': row[0]})\n",
    "        else:\n",
    "            gts[row[1]] = []\n",
    "            gts[row[1]].append(\n",
    "                {'image_id': row[1], 'cap_id': len(gts[row[1]]), 'caption': row[0]})\n",
    "    return gts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gts = convert_data_to_coco_scorer_format(gt_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = next(iter(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['labels'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sents_label = [' '.join([e for e in [vocab.get(str(key.data.tolist())) for key in data['labels'][ind]] if e not in ('<eos>', '<sos>')]) for ind in range(data['labels'].shape[0])] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feats_dir = 'data/feats/demo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix = 2211\n",
    "fc_feat = []\n",
    "fc_feat.append(np.load(os.path.join(feats_dir, 'video%i.npy' % (ix))))\n",
    "fc_feat = np.concatenate(fc_feat, axis=1)\n",
    "fc_feat = fc_feat[None, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fc_feat=torch.from_numpy(fc_feat).type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 40, 2048])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc_feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fc_feat = fc_feat.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chongke/anaconda3/envs/my_env/lib/python3.6/site-packages/torch/nn/functional.py:1339: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    }
   ],
   "source": [
    "# forward the model to also get generated samples for each image\n",
    "with torch.no_grad():\n",
    "    seq_probs, seq_preds = model(\n",
    "        fc_feat, mode='inference', opt=opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sents = utils.decode_sequence(vocab, seq_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "video_ids = 'video'+str(ix)\n",
    "sample_result = [video_ids, sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 150\n",
    "df_result = pd.DataFrame(sample_result).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_result.columns = ['id', 'inference']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>inference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>video2211</td>\n",
       "      <td>[a man is talking about a movie]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                         inference\n",
       "0  video2211  [a man is talking about a movie]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>caption</th>\n",
       "      <th>video_id</th>\n",
       "      <th>sen_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>155800</td>\n",
       "      <td>a man in suit is seated and talking a teacher is teaching in a classroom and students are taking down notes along with their laptops</td>\n",
       "      <td>video2211</td>\n",
       "      <td>155800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155801</td>\n",
       "      <td>a man with black suit talking in front of the camera</td>\n",
       "      <td>video2211</td>\n",
       "      <td>155801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155802</td>\n",
       "      <td>a man is answering  to the questions  related the work</td>\n",
       "      <td>video2211</td>\n",
       "      <td>155802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155803</td>\n",
       "      <td>there is a women in pink interiew a  well  designated man</td>\n",
       "      <td>video2211</td>\n",
       "      <td>155803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155804</td>\n",
       "      <td>two people in suit dress talking each other very seriously</td>\n",
       "      <td>video2211</td>\n",
       "      <td>155804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155805</td>\n",
       "      <td>a man in a suit discusses work within the cyber security and software engineering fields</td>\n",
       "      <td>video2211</td>\n",
       "      <td>155805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155806</td>\n",
       "      <td>woman interview the man and employees working in the office</td>\n",
       "      <td>video2211</td>\n",
       "      <td>155806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155807</td>\n",
       "      <td>a bald man wearing a suit speaks while sitting in an armchair</td>\n",
       "      <td>video2211</td>\n",
       "      <td>155807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155808</td>\n",
       "      <td>a man looking and talking with black color</td>\n",
       "      <td>video2211</td>\n",
       "      <td>155808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155809</td>\n",
       "      <td>guy dressed in formal wear answering to another guy</td>\n",
       "      <td>video2211</td>\n",
       "      <td>155809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155810</td>\n",
       "      <td>a man is speaking about software engineering how the development is done</td>\n",
       "      <td>video2211</td>\n",
       "      <td>155810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155811</td>\n",
       "      <td>a man in a black suit with a peach colored tie is talking to a woman in a pink shirt and vest</td>\n",
       "      <td>video2211</td>\n",
       "      <td>155811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155812</td>\n",
       "      <td>older woman is having conversation with man in black suit</td>\n",
       "      <td>video2211</td>\n",
       "      <td>155812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155813</td>\n",
       "      <td>woman in pink shirt is talking with handsome man</td>\n",
       "      <td>video2211</td>\n",
       "      <td>155813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155814</td>\n",
       "      <td>aold person  in black   color coat dress wearing cloth   speaking sitting  beside other lady  and many persons sitting on computer sir teaching on...</td>\n",
       "      <td>video2211</td>\n",
       "      <td>155814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155815</td>\n",
       "      <td>someone taking interview  and the linux class going</td>\n",
       "      <td>video2211</td>\n",
       "      <td>155815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155816</td>\n",
       "      <td>a older woman wearing a purple vest and pink shirt talks with a business man in a suit and tie calmly in an office setting about computer software</td>\n",
       "      <td>video2211</td>\n",
       "      <td>155816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155817</td>\n",
       "      <td>a person is being interviewed by a tv personnel saying about his studies of computer engineering cyber security</td>\n",
       "      <td>video2211</td>\n",
       "      <td>155817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155818</td>\n",
       "      <td>two people in professional attire are in an office talking</td>\n",
       "      <td>video2211</td>\n",
       "      <td>155818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155819</td>\n",
       "      <td>a bald man in a suit talking about it</td>\n",
       "      <td>video2211</td>\n",
       "      <td>155819</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                      caption  \\\n",
       "155800                   a man in suit is seated and talking a teacher is teaching in a classroom and students are taking down notes along with their laptops   \n",
       "155801                                                                                                   a man with black suit talking in front of the camera   \n",
       "155802                                                                                                 a man is answering  to the questions  related the work   \n",
       "155803                                                                                              there is a women in pink interiew a  well  designated man   \n",
       "155804                                                                                             two people in suit dress talking each other very seriously   \n",
       "155805                                                               a man in a suit discusses work within the cyber security and software engineering fields   \n",
       "155806                                                                                            woman interview the man and employees working in the office   \n",
       "155807                                                                                          a bald man wearing a suit speaks while sitting in an armchair   \n",
       "155808                                                                                                             a man looking and talking with black color   \n",
       "155809                                                                                                    guy dressed in formal wear answering to another guy   \n",
       "155810                                                                               a man is speaking about software engineering how the development is done   \n",
       "155811                                                          a man in a black suit with a peach colored tie is talking to a woman in a pink shirt and vest   \n",
       "155812                                                                                              older woman is having conversation with man in black suit   \n",
       "155813                                                                                                       woman in pink shirt is talking with handsome man   \n",
       "155814  aold person  in black   color coat dress wearing cloth   speaking sitting  beside other lady  and many persons sitting on computer sir teaching on...   \n",
       "155815                                                                                                    someone taking interview  and the linux class going   \n",
       "155816     a older woman wearing a purple vest and pink shirt talks with a business man in a suit and tie calmly in an office setting about computer software   \n",
       "155817                                        a person is being interviewed by a tv personnel saying about his studies of computer engineering cyber security   \n",
       "155818                                                                                             two people in professional attire are in an office talking   \n",
       "155819                                                                                                                  a bald man in a suit talking about it   \n",
       "\n",
       "         video_id  sen_id  \n",
       "155800  video2211  155800  \n",
       "155801  video2211  155801  \n",
       "155802  video2211  155802  \n",
       "155803  video2211  155803  \n",
       "155804  video2211  155804  \n",
       "155805  video2211  155805  \n",
       "155806  video2211  155806  \n",
       "155807  video2211  155807  \n",
       "155808  video2211  155808  \n",
       "155809  video2211  155809  \n",
       "155810  video2211  155810  \n",
       "155811  video2211  155811  \n",
       "155812  video2211  155812  \n",
       "155813  video2211  155813  \n",
       "155814  video2211  155814  \n",
       "155815  video2211  155815  \n",
       "155816  video2211  155816  \n",
       "155817  video2211  155817  \n",
       "155818  video2211  155818  \n",
       "155819  video2211  155819  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_dataframe.loc[gt_dataframe.index[gt_dataframe['video_id'] == video_ids]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
